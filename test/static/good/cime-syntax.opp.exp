File "cime-syntax.mly", line 42, characters 19-33:
Warning: the token DP_TERMINATION is unused.
File "cime-syntax.mly", line 38, characters 41-50:
Warning: the token GUILLEMET is unused.
File "cime-syntax.mly", line 46, characters 45-58:
Warning: the token LIBRE_UNIFIER is unused.
File "cime-syntax.mly", line 45, characters 7-15:
Warning: the token MATCHING is unused.
File "cime-syntax.mly", line 42, characters 7-18:
Warning: the token TERMINAISON is unused.
%{

open Abstract_syntax;;
open C_declare_operator;;
open Symbols;;
open Terms;;
open Equations;;
open Equations_as_obj;;
open Term_orderings;;
open Rpo;;
(*
open Norm_theory;;
*)
open Poly_interp;;
open Errors;;

let current_poly_vars = ref ([] : string list)
;;

let monome_de_variable var =
  try
    IntPolynomials.var (Listutils.index var !current_poly_vars)
  with Not_found -> semantical_error "Undeclared polynomial variable"
;;

%}
%start donnees
%start signature_eof
%start term_eof
%token AS
%token BINAIRE
%token COMPARER
%token COMPLETE
%token CONJECTURES
%token CONSTANTE
%token CRODROIT
%token CROGAUCHE
%token DEUX_POINTS
%token DP_TERMINATION
%token EGAL
%token EOF
%token EQUATIONS
%token EXP
%token FLECHE
%token GUILLEMET
%token <string> IDENT
%token INDUCTIVE
%token INFERIEUR
%token INFIXE
%token <string> INFIX_IDENT
%token <int> INT
%token KW_END
%token LIBRE_UNIFIER
%token LRLEX
%token MATCHER
%token MATCHING
%token MINUS
%token MUL
%token MULT
%token ONLY
%token OPERATEURS
%token ORDRE
%token PARDROITE
%token PARGAUCHE
%token PLAIN
%token PLUS
%token POINT_VIRGULE
%token <string> POLY_VAR
%token POSTFIXE
%token <string> POSTFIX_IDENT
%token PREFIXE
%token <string> PREFIX_IDENT
%token PROBLEMES
%token REDUIRE
%token RLLEX
%token SORTES
%token <string> STRING
%token SUBSORTES
%token SUPERIEUR
%token TERMINAISON
%token THEORIE
%token TOKEN_AC
%token TOKEN_C
%token TOKEN_INCLUDE
%token TOKEN_INTERACTIF
%token TOKEN_LEXICO
%token TOKEN_MAPO
%token TOKEN_POLY
%token TOKEN_RPO
%token TOKEN_RPS
%token TOKEN_SEMI_INTERACTIF
%token TOKEN_USER
%token TOKEN_VARIABLE
%token TYPE
%token UNAIRE
%token UNIFICATION
%token UNIFIER
%token VIRGULE
%token WITH
%left INFIX_IDENT TERMLIST
%nonassoc PARDROITE
%left MINUS PLUS
%left MULT
%nonassoc UMINUS
%right EXP
%type <Abstract_syntax.abstract_syntax list> donnees
%type <unit> signature_eof
%type <Terms.term> term_eof
%%

donnees:
  _1 = EOF
    {                         ( [] )}
| _1 = KW_END
    {                         ( [] )}
| _1 = declaration _2 = donnees
    {                         ( _1::_2 )}

declaration:
  _1 = TOKEN_INCLUDE _2 = STRING
    {                       (Abstract_include _2)}
| _1 = keyword_operators _2 = operateurs
    {                                 ( Abstract_operators _2 )}
| _1 = keyword_theory _2 = theorie
    {                              ( Abstract_theory _2 )}
| _1 = UNIFICATION _2 = keyword_theory _3 = theorie
    {                                       ( Abstract_unification_theory _3 )}
| _1 = UNIFICATION _2 = TYPE _3 = unif_type
    {                                ( Abstract_unification_type _3 )}
| _1 = keyword_axioms _2 = equations
    {                            ( Abstract_axioms _2 )}
| _1 = keyword_order _2 = ordre_plus
    {                            ( Abstract_ordering _2 )}
| _1 = keyword_problems _2 = problemes
    {                               ( Abstract_problems _2 )}
| _1 = keyword_conjectures _2 = equations
    {                                 ( Abstract_conjectures _2 )}
| _1 = keyword_sortes _2 = sortes
    {                                        ( Abstract_sortes _2)}
| _1 = keyword_subsortes _2 = subsortes
    {                                        ( Abstract_subsortes _2)}
| _1 = keyword_inductive _2 = equations
    {                                        ( Abstract_inductive _2 )}

keyword_operators:
  _1 = OPERATEURS
    {             (
  etat_analyse.top_allowed <- false;
  etat_analyse.lexer_state <- Ident_lexer )}

keyword_conjectures:
  _1 = CONJECTURES
    {              (
  etat_analyse.top_allowed <- false;
  etat_analyse.lexer_state <- Term_lexer )}

keyword_inductive:
  _1 = INDUCTIVE
    {            (
  etat_analyse.top_allowed <- false;
  etat_analyse.lexer_state <- Term_lexer )}

keyword_theory:
  _1 = THEORIE
    {          (
  etat_analyse.top_allowed <- false;
  etat_analyse.lexer_state <- Ident_lexer )}

keyword_axioms:
  _1 = EQUATIONS
    {            (
  etat_analyse.top_allowed <- false;
  etat_analyse.lexer_state <- Term_lexer )}

keyword_problems:
  _1 = PROBLEMES
    {            (
  etat_analyse.top_allowed <- false;
  etat_analyse.lexer_state <- Term_lexer )}

keyword_sortes:
  _1 = SORTES
    {         ( etat_analyse.lexer_state <- Ident_lexer )}

keyword_subsortes:
  _1 = SUBSORTES
    {              (etat_analyse.lexer_state <- Ident_lexer)}

subsortes:
  _1 = base_sorte _2 = INFERIEUR _3 = base_sorte
    {                                    ([(see_as_base_sort _1,see_as_base_sort _3)])}
| _1 = base_sorte _2 = INFERIEUR _3 = base_sorte _4 = VIRGULE _5 = subsortes
    {                                                    ((see_as_base_sort _1,see_as_base_sort _3):: _5 )}

sortes:
  _1 = base_sorte
    {               (make_new_sort _1)}
| _1 = base_sorte _2 = VIRGULE _3 = sortes
    {                            (make_new_sort _1 ; _3)}

keyword_order:
  _1 = ORDRE
    {        ( etat_analyse.lexer_state <- Standard_lexer )}

base_sorte:
  _1 = IDENT
    {          (_1)}

signature_eof:
  _1 = operateurs _2 = EOF
    {                        ( () )}

operateurs:
  _1 = decl_arite
    {                         ( [_1] )}
| _1 = decl_arite _2 = operateurs
    {                         ( _1::_2 )}
| _1 = decl_arite _2 = POINT_VIRGULE
    {                                       ( [_1] )}
| _1 = decl_arite _2 = POINT_VIRGULE _3 = operateurs
    {                                       ( _1::_3 )}

profile_list:
  _1 = profile
    {            ([_1])}
| _1 = profile _2 = VIRGULE _3 = profile_list
    {                                 (_1::_3)}

profile:
  _1 = base_sorte
    {             ([_1])}
| _1 = base_sorte _2 = FLECHE _3 = profile
    {                             (_1::_3)}

decl_arite:
  _1 = op_list_colon _2 = fix _3 = arity _4 = AS _5 = profile_list
    {    ( let t,a = _3 in
        if _2=INFIX & a<>2
          then raise (Erreur_de_syntaxe "Infix symbols must be binary")
          else
	  if (List.exists (fun x -> (List.length x-1)<>a) _5)
	  then raise (Erreur_de_syntaxe "Profile must be compatible with arity")
	  else
	    begin
	      (List.iter (definir_operateur t a _2 (List.map see_as_functional_sort _5)) _1);
	      (_1,_2,_3)
	    end
	    )}
| _1 = op_list_colon _2 = fix _3 = arity
    {    ( let t,a = _3 in
        if _2=INFIX & a<>2
          then raise (Erreur_de_syntaxe "Infix symbols must be binary")
          else
(* a virer *)
	  if (List.exists (fun x -> (List.length x-1)<>a) [])
	  then raise (Erreur_de_syntaxe "Profile must be compatible with arity")
	  else
	    begin
	      (List.iter (definir_operateur t a _2 (List.map see_as_functional_sort [])) _1);
(* jusque la *)
	      (_1,_2,_3)
	    end
	    )}

fix:
  _1 = PREFIXE
    {          ( PREFIX )}
| _1 = INFIXE
    {          ( INFIX  )}
| _1 = POSTFIXE
    {           ( POSTFIX )}
| 
    {          ( DEFAULT )}

arity:
  _1 = arityaux
    {                 ( etat_analyse.lexer_state <- Ident_lexer;_1 )}

arityaux:
  _1 = TOKEN_C
    {                 ( (C,2) )}
| _1 = TOKEN_AC
    {                 ( (AC,2) )}
| _1 = TOKEN_VARIABLE
    {                 ( (VARIABLE,0) )}
| _1 = CONSTANTE
    {                 ( (FREE,0) )}
| _1 = UNAIRE
    {                 ( (FREE,1) )}
| _1 = BINAIRE
    {                 ( (FREE,2) )}
| _1 = INT
    {                 ( (FREE,_1) )}

op_list_colon:
  _1 = op_list _2 = DEUX_POINTS
    {                      ( etat_analyse.lexer_state <- Standard_lexer; _1 )}

op_list:
  _1 = ident
    {                         ( [_1] )}
| _1 = ident _2 = VIRGULE _3 = op_list
    {                         ( _1::_3 )}

ident:
  _1 = IDENT
    {                      ( _1 )}

unif_type:
  _1 = TOKEN_AC _2 = ONLY
    {                      ( Unif_type_AC_only )}
| _1 = TOKEN_AC _2 = COMPLETE
    {                      ( Unif_type_AC_complete )}
| _1 = PLAIN
    {                      ( Unif_type_plain )}

theorie:
  _1 = decl_theorie
    {                       ( [_1] )}
| _1 = decl_theorie _2 = theorie
    {                       ( _1::_2 )}

decl_theorie:
  _1 = ident _2 = PARGAUCHE _3 = id_list_end
    {                              ( PRDF(_1::_3) )}
| _1 = keyword_user _2 = PARGAUCHE _3 = regle_list _4 = PARDROITE
    {                                              ( etat_analyse.lexer_state <- Ident_lexer;USR(_3) )}

id_list_end:
  _1 = ident _2 = PARDROITE
    {                             ( [_1] )}
| _1 = ident _2 = VIRGULE _3 = id_list_end
    {                             ( _1::_3 )}

keyword_user:
  _1 = TOKEN_USER
    {             ( etat_analyse.lexer_state <- Term_lexer )}

regle_list:
  _1 = regle
    {                                 ( [_1] )}
| _1 = regle _2 = POINT_VIRGULE _3 = regle_list
    {                                 ( _1::_3)}

regle:
  _1 = term _2 = FLECHE _3 = term
    {                                    ( make_basic_rule ((flatten_term _1),
                                                       (flatten_term _3)) )}

equations:
  _1 = equation _2 = POINT_VIRGULE
    {                                    ( [_1] )}
| _1 = equation _2 = POINT_VIRGULE _3 = equations
    {                                    ( _1::_3 )}

equation:
  _1 = term _2 = EGAL _3 = term
    {                                    ( new pair_of_terms (flatten_term _1)
                                      	(flatten_term _3) )}

ordre_plus:
  _1 = ordre
    {        ( _1 )}
| _1 = TOKEN_SEMI_INTERACTIF _2 = PARGAUCHE _3 = ordre _4 = PARDROITE
    {        ( SEMI_INTERACTIF(_3) )}

ordre:
  _1 = keyword_rpo _2 = PARGAUCHE _3 = precedence _4 = POINT_VIRGULE _5 = statuts _6 = PARDROITE
    {    ( RPO(_3,_5) )}
| _1 = keyword_rpo _2 = PARGAUCHE _3 = precedence _4 = PARDROITE
    {    ( RPO(_3,[]) )}
| _1 = keyword_mapo _2 = PARGAUCHE _3 = precedence _4 = PARDROITE
    {    ( MAPO(_3,[]) )}
| _1 = keyword_mapo _2 = PARGAUCHE _3 = precedence _4 = POINT_VIRGULE _5 = statuts _6 = PARDROITE
    {    ( MAPO(_3,_5) )}
| _1 = keyword_poly _2 = PARGAUCHE _3 = mu_value _4 = poly_decl_list _5 = PARDROITE
    {    ( POLY(_3,_4) )}
| _1 = TOKEN_INTERACTIF
    {    ( ORDRE_INTERACTIF )}
| _1 = TOKEN_LEXICO _2 = PARGAUCHE _3 = ordre_List
    {    ( LEXICO(_3) )}
| _1 = rps_header _2 = regle_list _3 = PARDROITE
    {    ( Rps(_1,_2) )}

rps_header:
  _1 = TOKEN_RPS _2 = PARGAUCHE _3 = ordre _4 = POINT_VIRGULE
    {    (
  etat_analyse.top_allowed <- true;
  etat_analyse.lexer_state <- Term_lexer;_3 )}

keyword_rpo:
  _1 = TOKEN_RPO
    {            (
  etat_analyse.top_allowed <- true;
  etat_analyse.lexer_state <- Ident_lexer )}

keyword_mapo:
  _1 = TOKEN_MAPO
    {             (
  etat_analyse.top_allowed <- true;
  etat_analyse.lexer_state <- Ident_lexer )}

mu_value:
  _1 = INT _2 = POINT_VIRGULE
    {             (
  etat_analyse.top_allowed <- true;
  etat_analyse.lexer_state <- Ident_lexer;_1 )}
| 
    {             (
  etat_analyse.top_allowed <- true;
  etat_analyse.lexer_state <- Ident_lexer;0 )}

keyword_poly:
  _1 = TOKEN_POLY
    {             ( etat_analyse.lexer_state <- Standard_lexer )}

ordre_List:
  _1 = ordre _2 = PARDROITE
    {                    ( [_1] )}
| _1 = ordre _2 = POINT_VIRGULE _3 = ordre_List
    {                                   ( _1::_3 )}

precedence:
  
    {                                        ( [] )}
| _1 = liste_ordonnee
    {                     ( [_1] )}
| _1 = liste_ordonnee _2 = VIRGULE _3 = precedence
    {                                    ( _1::_3 )}

liste_ordonnee:
  _1 = ident
    {             ( One_symbol (get_symbol_id _1) )}
| _1 = ident _2 = EGAL _3 = liste_ordonnee
    {                              ( Equal_to (get_symbol_id _1,_3) )}
| _1 = ident _2 = SUPERIEUR _3 = liste_ordonnee
    {                                  ( Greater_than (get_symbol_id _1,_3) )}
| _1 = ident _2 = INFERIEUR _3 = liste_ordonnee
    {                                  ( Lower_than (get_symbol_id _1,_3) )}

poly_decl_list:
  _1 = poly_decl
    {               ( [_1] )}
| _1 = poly_decl _2 = POINT_VIRGULE _3 = poly_decl_list
    {                                        ( _1::_3 )}

statuts:
  _1 = statut
    {                          ( [_1]   )}
| _1 = statut _2 = VIRGULE _3 = statuts
    {                          ( _1::_3 )}

statut:
  _1 = ident _2 = MUL
    {    ( (get_symbol_id _1),MULTISET
    )}
| _1 = ident _2 = lexstat
    {    ( let f=(get_symbol_id _1) in
      	if not (is_free f)
      	  then semantical_error	"Only free symbols can have a lexicographic status"
      	  else f,_2
    )}

lexstat:
  _1 = LRLEX
    {        ( LR_LEXICO )}
| _1 = RLLEX
    {        ( RL_LEXICO )}

problemes:
  _1 = probleme _2 = POINT_VIRGULE
    {                                    ( [_1] )}
| _1 = probleme _2 = POINT_VIRGULE _3 = problemes
    {                                    ( _1::_3 )}

probleme:
  _1 = term _2 = EGAL _3 = term
    {    ( EQUATION_A_PROUVER(flatten_term _1,flatten_term _3) )}
| _1 = REDUIRE _2 = term
    {    ( TERME_A_REDUIRE(flatten_term _2) )}
| _1 = unif_type _2 = UNIFIER _3 = term _4 = EGAL _5 = term
    {    ( EQUATION_A_RESOUDRE(_1,flatten_term _3,flatten_term _5) )}
| _1 = UNIFIER _2 = term _3 = EGAL _4 = term
    {    ( EQUATION_A_RESOUDRE(Unif_type_default,flatten_term _2,flatten_term _4) )}
| _1 = MATCHER _2 = term _3 = EGAL _4 = term
    {    ( EQUATION_A_MATCHER(flatten_term _2,flatten_term _4) )}
| _1 = COMPARER _2 = term _3 = WITH _4 = term
    {    ( TERMES_A_COMPARER(flatten_term _2,flatten_term _4) )}

poly_decl:
  _1 = entete_poly _2 = EGAL _3 = poly
    {    (
  etat_analyse.top_allowed <- true;
  etat_analyse.lexer_state <- Ident_lexer;
      (_1,_3)
      )}

entete_poly:
  _1 = CROGAUCHE _2 = poly_ident _3 = CRODROIT
    {    ( current_poly_vars := [];
      _2 )}
| _1 = CROGAUCHE _2 = poly_ident _3 = CRODROIT _4 = PARGAUCHE _5 = poly_var_list_end
    {    ( current_poly_vars := _5;

      let test_simple list =
      	let rec build_simple = function
      	    ([],l)	-> l
      	  | ((a::s), l)	-> build_simple (s,Listutils.union l [a])
      	in
	  if ( (List.length list)=(List.length (build_simple (list,[]))) )
	  then ()
	  else
	    semantical_error
	      "Same variable symbols in polynomial declaration"
      in
      	test_simple !current_poly_vars;

      	let f = _2 in
	  if (arity f)<>(List.length !current_poly_vars)
	  then semantical_error
	    ((string_of_symbol_id _2)^" is supposed to be a "
      	     ^(string_of_int (arity f))^"-ary operator")
	  else f
    )}

poly_ident:
  _1 = ident
    {        ( etat_analyse.lexer_state <- Poly_lexer;
      	  (get_symbol_id _1) )}

poly_var_list_end:
  _1 = POLY_VAR _2 = PARDROITE
    {                                      ( [_1] )}
| _1 = POLY_VAR _2 = VIRGULE _3 = poly_var_list_end
    {                                      ( _1::_3 )}

poly:
  _1 = POLY_VAR
    {    ( monome_de_variable _1 )}
| _1 = INT
    {    ( IntPolynomials.cte (Num.Int _1) )}
| _1 = PARGAUCHE _2 = poly _3 = PARDROITE
    {    ( _2 )}
| _1 = poly _2 = PLUS _3 = poly
    {    ( IntPolynomials.add _1 _3 )}
| _1 = poly _2 = MINUS _3 = poly
    {    ( IntPolynomials.sub _1 _3 )}
| _1 = MINUS _2 = poly %prec UMINUS
    {    ( IntPolynomials.minus _2 )}
| _1 = poly _2 = MULT _3 = poly
    {    ( IntPolynomials.mult _1 _3 )}
| _1 = poly _2 = EXP _3 = INT
    {    ( IntPolynomials.power _1 _3 )}

term:
  _1 = PREFIX_IDENT
    {   ( (* printf "forme a\n"; *)
      try
        VAR (var_id_of_string _1)
      with Not_found ->
        let f=(get_symbol_id _1) in
        if (arity f)=0
        then TERM(f,[])
        else semantical_error ("Bad number of arguments for " ^ _1)
     )}
| _1 = PARGAUCHE _2 = term _3 = PARDROITE
    {     ( _2
     )}
| _1 = PREFIX_IDENT _2 = PARGAUCHE _3 = term_list _4 = PARDROITE
    {     ( (* printf "forme f(...)\n"; *)
        let f=(get_symbol_id _1) in
        if (arity f)=(List.length _3)
        then TERM(f,_3)
        else semantical_error ("Bad number of arguments for " ^ _1)
    )}
| _1 = PARGAUCHE _2 = term _3 = PARDROITE _4 = POSTFIX_IDENT
    {    ( (* printf "forme f(...)\n"; *)
      let f=(get_symbol_id _4) in
        if (arity f)=1
          then TERM(f,[_2])
          else semantical_error ("Bad number of arguments for " ^ _4)
    )}
| _1 = PARGAUCHE _2 = term_list _3 = PARDROITE _4 = POSTFIX_IDENT
    {    ( (* printf "forme f(...)\n"; *)
      let f=(get_symbol_id _4) in
        if (arity f)=(List.length _2)
          then TERM(f,_2)
          else semantical_error ("Bad number of arguments for " ^ _4)
    )}
| _1 = term _2 = INFIX_IDENT _3 = term
    {    ( let f = (get_symbol_id _2) in
      TERM(f,[_1;_3])
    )}

term_list:
  _1 = term %prec TERMLIST
    {                      ( [_1] )}
| _1 = term _2 = VIRGULE _3 = term_list
    {                         ( _1 :: _3 )}

term_eof:
  _1 = term _2 = EOF
    {           ( _1 )}

%%
